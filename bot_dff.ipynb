{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8c0e72b-bef2-45ab-8ac5-bea2f95d3396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 16 16:55:03 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.156.00   Driver Version: 450.156.00   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM3...  On   | 00000000:39:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    56W / 350W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1666907-9216-4551-85e4-977356c9d3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: df_engine in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (0.9.0)\n",
      "Requirement already satisfied: pydantic>=1.8.2 in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from df_engine) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/user/conda/lib/python3.7/site-packages (from pydantic>=1.8.2->df_engine) (4.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install df_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f16f5739-33be-43d6-8024-b85bfde85e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasttext in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (0.9.2)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from fasttext) (60.5.0)\n",
      "Requirement already satisfied: pybind11>=2.2 in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from fasttext) (2.9.2)\n",
      "Requirement already satisfied: numpy in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from fasttext) (1.18.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d94ecb5e-7251-4e9f-bd24-6ee1215a00b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic==1.8.2 in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (1.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/user/conda/lib/python3.7/site-packages (from pydantic==1.8.2) (4.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydantic==1.8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "180fc5b4-6d1e-4c68-b9f5-23fd7aecc0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.10.3 in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (4.10.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/user/conda/lib/python3.7/site-packages (from transformers==4.10.3) (6.0)\n",
      "Requirement already satisfied: sacremoses in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from transformers==4.10.3) (0.0.35)\n",
      "Requirement already satisfied: requests in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from transformers==4.10.3) (2.22.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from transformers==4.10.3) (1.18.0)\n",
      "Requirement already satisfied: packaging in /home/user/conda/lib/python3.7/site-packages (from transformers==4.10.3) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/user/conda/lib/python3.7/site-packages (from transformers==4.10.3) (2022.1.18)\n",
      "Requirement already satisfied: importlib-metadata in /home/user/conda/lib/python3.7/site-packages (from transformers==4.10.3) (4.10.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.12 in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from transformers==4.10.3) (0.5.1)\n",
      "Requirement already satisfied: filelock in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from transformers==4.10.3) (3.0.12)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from transformers==4.10.3) (0.10.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from transformers==4.10.3) (4.62.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/user/conda/lib/python3.7/site-packages (from huggingface-hub>=0.0.12->transformers==4.10.3) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/user/conda/lib/python3.7/site-packages (from packaging->transformers==4.10.3) (3.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/user/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.10.3) (3.7.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from requests->transformers==4.10.3) (1.25.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from requests->transformers==4.10.3) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/conda/lib/python3.7/site-packages (from requests->transformers==4.10.3) (2021.10.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from requests->transformers==4.10.3) (3.0.4)\n",
      "Requirement already satisfied: six in /home/user/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.10.3) (1.16.0)\n",
      "Requirement already satisfied: click in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from sacremoses->transformers==4.10.3) (7.1.2)\n",
      "Requirement already satisfied: joblib in /home/user/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.10.3) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.10.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9938864f-afaf-4690-baaa-37f41bb6f161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googletrans==3.1.0a0 in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (3.1.0a0)\n",
      "Requirement already satisfied: httpx==0.13.3 in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from googletrans==3.1.0a0) (0.13.3)\n",
      "Requirement already satisfied: certifi in /home/user/conda/lib/python3.7/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2021.10.8)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.5.0)\n",
      "Requirement already satisfied: sniffio in /home/user/conda/lib/python3.7/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.2.0)\n",
      "Requirement already satisfied: idna==2.* in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.8)\n",
      "Requirement already satisfied: httpcore==0.9.* in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (0.9.1)\n",
      "Requirement already satisfied: hstspreload in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2021.12.1)\n",
      "Requirement already satisfied: chardet==3.* in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (0.9.0)\n",
      "Requirement already satisfied: h2==3.* in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.2.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in /home/jovyan/.imgenv-oleg-mgpt-0/lib/python3.7/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install googletrans==3.1.0a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdd0ee67-d8fe-45c7-b737-5b6121349082",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-16 16:55:18.197972: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.10.3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcf1edb7-a219-4e5d-8b65-cfd7da1c25f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, BertConfig, GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Union\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import logging\n",
    "import re\n",
    "from typing import Optional, Union, Any\n",
    "from df_engine.core.keywords import TRANSITIONS, RESPONSE\n",
    "from df_engine.core import Context, Actor\n",
    "import df_engine.conditions as cnd\n",
    "import df_engine.labels as lbl\n",
    "from df_engine.core.types import NodeLabel3Type\n",
    "import os\n",
    "import requests\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c9b7a9f-5421-4c87-8a2e-af0df636bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intentcls starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae12de99-2103-4ece-aa86-0ba4de817b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig.from_pretrained(\"sentence-transformers/LaBSE\", num_labels=86)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"sentence-transformers/LaBSE\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e690728-aaab-495c-b00c-a30e0a56f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load\n",
    "model_state_dict = torch.load(\"best_model_state.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c50a78e-fed3-42b0-a935-952a0b2c8535",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df_train_translated_new.csv\", encoding=\"latin1\").fillna(method=\"ffill\")\n",
    "class_names = {}\n",
    "\n",
    "for w, t in zip(df[\"intents_nums\"], df[\"intent\"]):\n",
    "      class_names[w] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "845a5a9c-eaec-4de4-b62c-a461efdaf245",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"sentence-transformers/LaBSE\", state_dict=model_state_dict)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "  \n",
    "    def forward(self, input_ids, attention_mask, return_dict):\n",
    "        _, pooled_output = self.bert(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        return_dict = False\n",
    "    )\n",
    "        output = self.drop(pooled_output)\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f681095c-f89d-4f10-8b84-405c83549d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sentence-transformers/LaBSE were not used when initializing BertModel: ['out.weight', 'out.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_loaded = SentimentClassifier(len(class_names))\n",
    "model_loaded.load_state_dict(model_state_dict)\n",
    "model_loaded.to(device)\n",
    "model_loaded = model_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "962338fb-391d-4920-96e8-709dc44a6295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intents(model,text):\n",
    "    encoded_text = tokenizer.encode_plus(\n",
    "    text,\n",
    "    max_length=160,\n",
    "    add_special_tokens=True,\n",
    "    return_token_type_ids=False,\n",
    "    padding = 'max_length',\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt',\n",
    "    )\n",
    "    input_ids = encoded_text['input_ids'].to(device)\n",
    "    attention_mask = encoded_text['attention_mask'].to(device)\n",
    "\n",
    "    output = model(input_ids, attention_mask, return_dict=False)\n",
    "    _, preds = torch.max(output, dim=1)\n",
    "    return class_names[int(preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ade12e10-db5a-4540-aa12-4b3044ea94ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request_addr\n"
     ]
    }
   ],
   "source": [
    "print(get_intents(model_loaded, 'and its address'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b45fde8-8672-4a0d-a222-98e484499742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ner starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79457d5b-d0d4-42b2-88e4-b8dad68390b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_gpt = GPT2Tokenizer.from_pretrained(\"sberbank-ai/mGPT\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"sberbank-ai/mGPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4eec0cf8-d111-4c02-8a14-8ca444d09a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbd2a596-c2cf-4c3d-9f53-cfa914a856f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lang = 'en'\n",
    "prompts = {0: \"<s>lang: \", 1: \"\\nTagged sentence: \", 2: '</s>'}\n",
    "def format_train_data(sent):\n",
    "    sent = sent.replace('\\n','@@@')\n",
    "    sent = re.sub(r'\\s+', ' ', sent)\n",
    "    sent = sent.replace(' ','_')\n",
    "    sent = ' '.join(random.choices(re.sub('@@@', ' ', sent).strip().split(), k=45))\n",
    "    result = prompts[0] +train_lang+ prompts[1] +sent+ prompts[2]\n",
    "    return result\n",
    "\n",
    "def format_test_data(sent, i, lang):\n",
    "    sent = sent.replace('\\n','@@@')\n",
    "    sent = re.sub(r'\\s+', ' ', sent)\n",
    "    sent = sent.replace(' ','_')\n",
    "    sent = re.sub('@@@', ' ', sent).strip().split()\n",
    "    result = prompts[0] +lang+ prompts[1] +' '.join(sent[:i]) + ' ' \\\n",
    "             + sent[i].split('_')[0] + '_'\n",
    "    return ' '.join(sent[:i]) + ' ' + sent[i].split('_')[0] + '_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e8addd3-73d9-4387-a741-0efa69401a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagset = {line.strip().split()[-1] for line in open(\"en_data/train.txt\") if line.strip()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3185db7-557e-4872-8aa7-e665cbcc07f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data = format_test_data(open(\"en_data/test.txt\").read(), 42, 'en')\n",
    "de_data = format_test_data(open(\"de_data/valid.txt\").read(), 42, 'de')\n",
    "ru_data = format_test_data(open(\"ru_data/train.txt\").read(), 42, 'ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4edea3b-144a-42b5-b0e5-84cd646b6152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypotheses(sent):\n",
    "    pref = en_data+de_data+ru_data+sent\n",
    "    hyps = [pref+tag for tag in tagset]\n",
    "    return hyps, tagset\n",
    "\n",
    "def choose_tag(sentence):\n",
    "    losses = {}\n",
    "    hyps, tagset = hypotheses(sentence)\n",
    "    for tag, hyp in zip(tagset, hyps):\n",
    "        input_ids = tokenizer_gpt.encode(hyp, return_tensors='pt').cuda(device)\n",
    "        model_output = model.forward(input_ids, labels=input_ids)\n",
    "        losses[tag] = float(model_output[\"loss\"].cpu().detach().numpy())\n",
    "    return min(losses, key=losses.get)\n",
    "\n",
    "def get_ner_tags(text_to_tag):\n",
    "    text_tokens = text_to_tag.split()\n",
    "    sentence = ''\n",
    "    text_tags = []\n",
    "    result = {}\n",
    "    for token in text_tokens:\n",
    "        sentence += token+'_'\n",
    "        next_tag = choose_tag(sentence)\n",
    "        text_tags.append(next_tag)\n",
    "        sentence += next_tag+ ' '\n",
    "    for word, tag in zip(text_to_tag.split(), text_tags):\n",
    "        result[word] = tag\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04844879-9ff4-4205-a172-704993ccc8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'japanese': 'B-food', 'restaurant': 'O'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ner_tags('japanese restaurant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcb92cb5-b154-4325-997c-798f244e450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#language detection and translation starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6dee486-a6b6-4d4d-b7dc-41b8d4f82038",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['nördAichen und Stadt orientalisch Restaurant', 'Ажылдаар ужурлуг мен', 'Китайский ресторан', 'cuisine japonaise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2802f46e-2c09-4d5b-a18b-31e9a7492c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de\n",
      "ky\n",
      "ru\n",
      "fr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "fst = fasttext.load_model('lid.176.bin')\n",
    "for text in texts:\n",
    "    print(fst.predict(text, k=1)[0][0].replace('__label__',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6f6c0ae-e316-460c-969e-e3abd0d471ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Какую часть города вы имеете в виду?\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator, constants\n",
    "translator = Translator()\n",
    "translation = translator.translate('What part of town do you have in mind?', dest=\"ru\")\n",
    "print(translation.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a138c4d-63e7-4b30-9f50-8605fb567f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#database processing and connecting starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83253947-2bde-4b7d-9efe-d0b3cc1fbc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('akadem.txt') as f:\n",
    "    db_results = f.read()\n",
    "import ast\n",
    "db_results = db_results.replace('\\u200b', '')\n",
    "database = ast.literal_eval(db_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e5de2c5-88be-4351-8590-6a0b1e770212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Гуси ресторан-пивоварня', 'food': 'европейская', 'pricerange': '$$ - $$$', 'area': 'нижняя зона', 'addr': 'Николаева, 12/2, 1 этаж, Академгородок м-н, Советский район, Новосибирск', 'phone': '+7 (383) 310-16-03', 'postcode': '630090'}\n"
     ]
    }
   ],
   "source": [
    "print(database[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2e48c66-386a-4ee2-abaf-0dc388681677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Клевер Айриш Паб']\n"
     ]
    }
   ],
   "source": [
    "food = 'ирландская'\n",
    "area = 'верхняя зона'\n",
    "pricerange = '$$ - $$$'\n",
    "result = []\n",
    "for i in range(len(database)):\n",
    "    if ('food', food) in database[i].items() and ('area', area) in database[i].items() and ('pricerange', pricerange) in database[i].items():\n",
    "        result.append(database[i]['name'])\n",
    "               \n",
    "print(result)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5cc446e0-c58f-4dca-a447-338a7b29a9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bot starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5f5e265-105e-4aab-b275-44c18b263b93",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_63415/1353092149.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    401\u001b[0m     )\n\u001b[1;32m    402\u001b[0m     \u001b[0;31m#run_test()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m     \u001b[0mrun_interactive_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_63415/1353092149.py\u001b[0m in \u001b[0;36mrun_interactive_mode\u001b[0;34m(actor)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0min_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"type your answer: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mturn_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m         )\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1090\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def unknown_slots(ctx: Context):\n",
    "    if \"slots\" not in ctx.misc.keys() or not ctx.misc['slots']:\n",
    "         ctx.misc[\"slots\"] = {\n",
    "             \"food\": None,\n",
    "             \"pricerange\": None,\n",
    "             \"area\": None,\n",
    "             \"phone\": None,\n",
    "             \"addr\": None,\n",
    "             \"postcode\": None,\n",
    "             \"name\": None}\n",
    "    ctx.misc[\"unknown_slots\"] = []\n",
    "    for key, value in ctx.misc[\"slots\"].items():\n",
    "        if value is None:\n",
    "            ctx.misc['unknown_slots'].append(key)\n",
    "    print(\"unknown slots\", ctx.misc[\"slots\"])\n",
    "    return ctx\n",
    "\n",
    "\n",
    "def get_some_intent(ctx: Context, actor: Actor):\n",
    "    request = ctx.last_request\n",
    "    intent = get_intents(model_loaded, request)\n",
    "    detected_language = fst.predict(request, k=1)[0][0].replace('__label__','')\n",
    "    ctx.misc[\"intent_detection\"] = {request: intent}\n",
    "    ctx.misc[\"language\"] = {request: detected_language}\n",
    "    return ctx\n",
    "\n",
    "\n",
    "def get_ner_tag(ctx: Context, actor: Actor):\n",
    "    unknown_slots(ctx)\n",
    "    request = ctx.last_request\n",
    "    request_slots = get_ner_tags(request)\n",
    "    print('GET NER TAG', request_slots)\n",
    "    for key, value in request_slots.items():\n",
    "        if value == 'O':\n",
    "            pass\n",
    "        elif value.split('-')[1].endswith(\"pricerange\"):\n",
    "            ctx.misc[\"slots\"][\"pricerange\"] = key\n",
    "        elif value.split('-')[1].endswith(\"area\"):\n",
    "            ctx.misc[\"slots\"][\"area\"] = key\n",
    "        elif value.split('-')[1].endswith(\"food\"):\n",
    "            ctx.misc[\"slots\"][\"food\"] = key\n",
    "    unknown_slots(ctx)\n",
    "    return ctx\n",
    "\n",
    "\n",
    "def turn_handler(\n",
    "    in_request: str, ctx: Union[Context, str, dict], actor: Actor, true_out_response: Optional[str] = None\n",
    "):\n",
    "    ctx = Context.cast(ctx)\n",
    "    ctx.add_request(in_request)\n",
    "\n",
    "    ctx.misc['unknown_slots'] = []\n",
    "    ctx.misc[\"intent_detection\"] = {}\n",
    "    ctx.misc[\"language\"] = {} \n",
    "    request = ctx.last_request\n",
    "    get_some_intent(ctx, actor)\n",
    "    get_ner_tag(ctx, actor)\n",
    "    \n",
    "    ctx = actor(ctx)\n",
    "    out_response = ctx.last_response\n",
    "    print(ctx.misc)\n",
    "    if true_out_response is not None and true_out_response != out_response:\n",
    "        msg = f\"in_request={in_request} -> true_out_response != out_response: {true_out_response} != {out_response}\"\n",
    "        raise Exception(msg)\n",
    "    else:\n",
    "        logging.info(f\"in_request={in_request} -> {out_response}\")\n",
    "    return out_response, ctx\n",
    "\n",
    "\n",
    "def get_item_from_db(ctx: Context):\n",
    "    pricerange = ''\n",
    "    area = ''\n",
    "    food = ''\n",
    "    if ctx.misc['slots']['pricerange'] == 'дешёвый' or ctx.misc['slots']['pricerange'] == 'cheap':\n",
    "        pricerange = '$'\n",
    "    elif ctx.misc['slots']['pricerange'] == 'средний' or ctx.misc['slots']['pricerange'] == 'moderate':\n",
    "        pricerange = '$$'\n",
    "    elif ctx.misc['slots']['pricerange'] == 'дорогой' or ctx.misc['slots']['pricerange'] == 'expensive':\n",
    "        pricerange = '$$ - $$$'\n",
    "    \n",
    "    \n",
    "    if ctx.misc['slots']['food'] == 'итальянский' or ctx.misc['slots']['food'] == 'italian' or ctx.misc['slots']['food'] == 'italien':\n",
    "        food = 'итальянская'\n",
    "    elif ctx.misc['slots']['food'] == 'японский' or ctx.misc['slots']['food'] == 'japanese' or ctx.misc['slots']['food'] == 'japonais':\n",
    "        food = 'японская'\n",
    "    elif ctx.misc['slots']['food'] == 'европейский' or ctx.misc['slots']['food'] == 'european' or ctx.misc['slots']['food'] == 'europeen':\n",
    "        food = 'европейская'\n",
    "    elif ctx.misc['slots']['food'] == 'американский' or ctx.misc['slots']['food'] == 'american' or ctx.misc['slots']['food'] == 'americain':\n",
    "        food = 'американская'\n",
    "    elif ctx.misc['slots']['food'] == 'ирландский' or ctx.misc['slots']['food'] == 'irish' or ctx.misc['slots']['food'] == 'irlandais':\n",
    "        food = 'ирландская'\n",
    "        \n",
    "    if ctx.misc['slots']['area'] == 'west' or ctx.misc['slots']['area'] == \"l'ouest\" or ctx.misc['slots']['area'] == 'запад':\n",
    "        area = 'верхняя зона'\n",
    "    elif ctx.misc['slots']['area'] == 'south' or ctx.misc['slots']['area'] == \"sud\" or ctx.misc['slots']['area'] == 'юг':\n",
    "        area = 'верхняя зона'\n",
    "    elif ctx.misc['slots']['area'] == 'north' or ctx.misc['slots']['area'] == \"nord\" or ctx.misc['slots']['area'] == 'север':\n",
    "        area = 'нижняя зона'    \n",
    "    elif ctx.misc['slots']['area'] == 'east' or ctx.misc['slots']['area'] == \"l'est\" or ctx.misc['slots']['area'] == 'восток':\n",
    "        area = 'нижняя зона'\n",
    "    \n",
    "    result = []\n",
    "    for i in range(len(database)):\n",
    "        if ('food', food) in database[i].items() and ('area', area) in database[i].items() and ('pricerange', pricerange) in database[i].items():\n",
    "            result.append(database[i]['name'])\n",
    "    num_results = len(result)\n",
    "    if num_results != 0:\n",
    "        response = f\"I've found {num_results} results. {''.join(result)} is a great restaurant for you.\"\n",
    "    else:\n",
    "        response = f\"Unfortunately I've found {num_results} results.\"\n",
    "    return response\n",
    "\n",
    "def central_response(ctx: Context, actor: Actor, *args, **kwargs) -> Any:\n",
    "    request = ctx.last_request\n",
    "    if \"slots\" not in ctx.misc.keys():\n",
    "         ctx.misc[\"slots\"] = {\n",
    "             \"food\": None,\n",
    "             \"pricerange\": None,\n",
    "             \"area\": None,\n",
    "             \"phone\": None,\n",
    "             \"addr\": None,\n",
    "             \"postcode\": None,\n",
    "             \"name\": None}\n",
    "    if \"unknown_slots\" not in ctx.misc.keys():\n",
    "         ctx.misc[\"unknown_slots\"] = []\n",
    "    if \"language\" not in ctx.misc.keys():\n",
    "        ctx.misc[\"language\"] = {}\n",
    "    unkn_slots = ctx.misc[\"unknown_slots\"]\n",
    "    if request == 'text':\n",
    "        pass\n",
    "    else:\n",
    "        necessary = ['food', 'pricerange', 'area']\n",
    "        language = ctx.misc[\"language\"][request]\n",
    "        if not any(x in necessary for x in unkn_slots):\n",
    "            response = get_item_from_db(ctx)\n",
    "            if language == 'en':\n",
    "                return response\n",
    "            else:\n",
    "                translation = translator.translate(response, dest=language)\n",
    "                return translation.text\n",
    "        else:\n",
    "            necessary = ['food', 'pricerange', 'area']\n",
    "            for v in necessary:\n",
    "                if v in unkn_slots:\n",
    "                    response = f\"What {v} do you have in mind?\"\n",
    "                    if language == 'en':\n",
    "                        return response\n",
    "                    else:\n",
    "                        translation = translator.translate(response, dest=language)\n",
    "                        return translation.text \n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "\n",
    "def custom_condition(ctx: Context, actor: Actor, *args, **kwargs) -> bool:\n",
    "    try:\n",
    "        necessary = ['food', 'pricerange', 'area']\n",
    "        if any(x in necessary for x in ctx.misc['unknown_slots']):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except KeyError:\n",
    "        return True\n",
    "\n",
    "def not_custom_condition(ctx: Context, actor: Actor, *args, **kwargs) -> bool:\n",
    "    return not custom_condition(ctx, actor, *args, **kwargs)\n",
    "\n",
    "def central_condition(ctx: Context, actor: Actor, *args, **kwargs) -> bool:\n",
    "    try:\n",
    "        request = ctx.last_request\n",
    "        if 'inform' in ctx.misc[\"intent_detection\"][request]:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except KeyError:\n",
    "        return True   \n",
    "\n",
    "\n",
    "def hi_condition(ctx: Context, actor: Actor, *args, **kwargs) -> bool:\n",
    "    try:\n",
    "        request = ctx.last_request\n",
    "        if ctx.misc[\"intent_detection\"][request] == 'hello':\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except KeyError:\n",
    "        return True\n",
    "    \n",
    "def hi_response(ctx: Context, actor: Actor, *args, **kwargs) -> Any:\n",
    "    request = ctx.last_request\n",
    "    if \"language\" not in ctx.misc.keys():\n",
    "        ctx.misc[\"language\"] = {}\n",
    "    if request == 'text':\n",
    "        pass\n",
    "    else:        \n",
    "        language = ctx.misc[\"language\"][request]\n",
    "        response = \"Hello, welcome to the Cambridge restaurant system. You can ask for restaurants by area, price range or food type. How may I help you?\"\n",
    "        if language == 'en':\n",
    "             return response\n",
    "        else:\n",
    "            translation = translator.translate(response, dest=language)\n",
    "            return translation.text \n",
    "    \n",
    "    \n",
    "def bye_condition(ctx: Context, actor: Actor, *args, **kwargs) -> bool:\n",
    "    try:\n",
    "        request = ctx.last_request\n",
    "        if 'bye' in ctx.misc[\"intent_detection\"][request]:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except KeyError:\n",
    "        return True\n",
    "    \n",
    "def bye_response(ctx: Context, actor: Actor, *args, **kwargs) -> Any:\n",
    "    request = ctx.last_request\n",
    "    if \"language\" not in ctx.misc.keys():\n",
    "        ctx.misc[\"language\"] = {}\n",
    "    if request == 'text':\n",
    "        pass\n",
    "    else:\n",
    "        language = ctx.misc[\"language\"][request]\n",
    "        response = 'Thank you for using Cambridge restaurant system! Goodbye!'\n",
    "        if language == 'en':\n",
    "             return response\n",
    "        else:\n",
    "            translation = translator.translate(response, dest=language)\n",
    "            return translation.text \n",
    "\n",
    "    \n",
    "def request_condition(ctx: Context, actor: Actor, *args, **kwargs) -> bool:\n",
    "    try:\n",
    "        request = ctx.last_request\n",
    "        if 'request' in ctx.misc[\"intent_detection\"][request]:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except KeyError:\n",
    "        return True\n",
    "    \n",
    "def request_response(ctx: Context, actor: Actor, *args, **kwargs) -> Any:\n",
    "    request = ctx.last_request\n",
    "    if \"language\" not in ctx.misc.keys():\n",
    "        ctx.misc[\"language\"] = {}\n",
    "    if request == 'text':\n",
    "        pass\n",
    "    else:\n",
    "        language = ctx.misc[\"language\"][request]\n",
    "        response = \"Sorry, I'm still developing, now I don't work with requests\"\n",
    "        if language == 'en':\n",
    "             return response\n",
    "        else:\n",
    "            translation = translator.translate(response, dest=language)\n",
    "            return translation.text\n",
    "\n",
    "    \n",
    "def fallback_response(ctx: Context, actor: Actor, *args, **kwargs) -> Any:\n",
    "    request = ctx.last_request\n",
    "    if \"language\" not in ctx.misc.keys():\n",
    "        ctx.misc[\"language\"] = {}\n",
    "    if request == 'text':\n",
    "        pass\n",
    "    else:\n",
    "        language = ctx.misc[\"language\"][request]\n",
    "        response = \"Sorry, I don't understand. Could you make it more clear?\"\n",
    "        if language == 'en':\n",
    "             return response\n",
    "        else:\n",
    "            translation = translator.translate(response, dest=language)\n",
    "            return translation.text    \n",
    "        \n",
    "        \n",
    "def fallback_condition(ctx: Context, actor: Actor, *args, **kwargs) -> bool:\n",
    "    try:\n",
    "        request = ctx.last_request\n",
    "        if 'unknown' in ctx.misc[\"intent_detection\"][request]:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except KeyError:\n",
    "        return True  \n",
    "\n",
    "\n",
    "def print_misc(ctx: Context, actor: Actor):\n",
    "    print(f\"{ctx.misc}\")\n",
    "    return ctx\n",
    "    \n",
    "    \n",
    "script = {\n",
    "    \"global_flow\": {\n",
    "        \"start_node\": {  \n",
    "            RESPONSE: \"\",\n",
    "            TRANSITIONS: {\n",
    "                (\"global_flow\", \"greeting_node\"): hi_condition, \n",
    "                (\"global_flow\", \"central_node\"): central_condition,\n",
    "                (\"global_flow\", \"request_node\"): request_condition,\n",
    "                (\"global_flow\", \"bye_node\"): bye_condition,\n",
    "                lbl.to_fallback(): fallback_condition,\n",
    "            },\n",
    "        },\n",
    "        \"fallback_node\": {  # We get to this node if an error occurred while the agent was running\n",
    "            RESPONSE: fallback_response,\n",
    "            TRANSITIONS: {\n",
    "                (\"global_flow\", \"greeting_node\"): hi_condition,\n",
    "                (\"global_flow\", \"request_node\"): request_condition,\n",
    "                (\"global_flow\", \"central_node\"): central_condition,\n",
    "                (\"global_flow\", \"bye_node\"): bye_condition,\n",
    "            },\n",
    "        },\n",
    "        \"greeting_node\": {\n",
    "            RESPONSE: hi_response,\n",
    "            TRANSITIONS: {\n",
    "                lbl.repeat(): hi_condition,\n",
    "                (\"global_flow\", \"central_node\"): central_condition,\n",
    "                (\"global_flow\", \"request_node\"): request_condition,\n",
    "                lbl.to_fallback(): fallback_condition,\n",
    "                (\"global_flow\", \"bye_node\"): bye_condition,\n",
    "            },\n",
    "        },\n",
    "        \"central_node\": {\n",
    "            RESPONSE: central_response, \n",
    "            TRANSITIONS: {\n",
    "                (\"global_flow\", \"greeting_node\"): hi_condition,\n",
    "                (\"global_flow\",\"bye_node\"): bye_condition,\n",
    "                (\"global_flow\", \"request_node\"): request_condition,\n",
    "                lbl.repeat(): not_custom_condition,\n",
    "                lbl.repeat(): custom_condition,\n",
    "            },\n",
    "        },\n",
    "        \"bye_node\": {\n",
    "            RESPONSE: bye_response,\n",
    "            TRANSITIONS: {\n",
    "                lbl.repeat(): bye_condition,\n",
    "                (\"global_flow\", \"greeting_node\"): hi_condition,\n",
    "                (\"global_flow\", \"central_node\"): central_condition,\n",
    "                (\"global_flow\", \"request_node\"): request_condition,\n",
    "                lbl.to_fallback(): fallback_condition, \n",
    "            },\n",
    "        },\n",
    "        \"request_node\": {\n",
    "            RESPONSE: request_response,\n",
    "            TRANSITIONS: {\n",
    "                lbl.repeat(): request_condition,\n",
    "                (\"global_flow\", \"greeting_node\"): hi_condition,\n",
    "                (\"global_flow\", \"central_node\"): central_condition,\n",
    "                lbl.to_fallback(): fallback_condition,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "actor = Actor(\n",
    "    script,\n",
    "    start_label=(\"global_flow\", \"start_node\"),\n",
    "    fallback_label=(\"global_flow\", \"fallback_node\"),\n",
    "    label_priority=1.0,\n",
    ")\n",
    "\n",
    "\n",
    "# testing\n",
    "testing_dialog = [\n",
    "    (\"hi\", \"Hello, welcome to the Cambridge restaurant system. You can ask for restaurants by area, price range or food type. How may I help you?\"),\n",
    "    (\"i'm fine, how are you?\", \"Good. What do you want to talk about?\"),\n",
    "    (\"i want cheap restaurant.\", \"What kind of food would you like?\"),\n",
    "    (\"chinese\", \"Would you like something in the cheap, moderate, or expensive price range?\"),\n",
    "    (\"cheap\", \"What part of town do you have in mind?\"),\n",
    "    (\"west\", \"API REQUEST.\"),\n",
    "    (\"next\", \"Good. What do you want to talk about?\"),\n",
    "    (\"previous\", \"That's all what I know\"),\n",
    "    (\"next time\", \"bye\"),\n",
    "    (\"stop\", \"Ooops\"),\n",
    "    (\"previous\", \"bye\"),\n",
    "    (\"stop\", \"Ooops\"),\n",
    "    (\"nope\", \"Ooops\"),\n",
    "    (\"hi\", \"Hi, how are you?\"),\n",
    "    (\"stop\", \"Ooops\"),\n",
    "    (\"Ok, goodbye.\", \"bye\"),\n",
    "]\n",
    "\n",
    "\n",
    "def run_test():\n",
    "    ctx = {}\n",
    "    for in_request, true_out_response in testing_dialog:\n",
    "        _, ctx = turn_handler(in_request, ctx, actor, true_out_response=true_out_response)\n",
    "\n",
    "\n",
    "# interactive mode\n",
    "def run_interactive_mode(actor):\n",
    "    ctx = {}\n",
    "    while True:\n",
    "        in_request = input(\"type your answer: \")\n",
    "        _, ctx = turn_handler(in_request, ctx, actor)\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s-%(name)15s:%(lineno)3s:%(funcName)20s():%(levelname)s - %(message)s\", level=logging.INFO\n",
    "    )\n",
    "    #run_test()\n",
    "    run_interactive_mode(actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c121b07-2b80-4369-9733-226b83428543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#something for telegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc79acf-983e-4e49-b69a-1abb6b79c1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install df-telegram-connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d31fee5-2c2f-417d-b75d-12966e392dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from df_telegram_connector.connector import TelegramConnector\n",
    "from df_telegram_connector.request_provider import PollingRequestProvider\n",
    "\n",
    "from df_runner import ScriptRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b91b50-9dcf-4a29-b06a-bbda0fb76e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown slots {'food': None, 'pricerange': None, 'area': None, 'phone': None, 'addr': None, 'postcode': None, 'name': None}\n",
      "GET NER TAG {'привет': 'O'}\n",
      "unknown slots {'food': None, 'pricerange': None, 'area': None, 'phone': None, 'addr': None, 'postcode': None, 'name': None}\n",
      "{'intent_detection': {'привет': 'hello'}, 'language': {'привет': 'ru'}, 'slots': {'food': None, 'pricerange': None, 'area': None, 'phone': None, 'addr': None, 'postcode': None, 'name': None}, 'unknown_slots': ['food', 'pricerange', 'area', 'phone', 'addr', 'postcode', 'name']}\n",
      "unknown slots {'food': None, 'pricerange': None, 'area': None, 'phone': None, 'addr': None, 'postcode': None, 'name': None}\n",
      "GET NER TAG {'expensive': 'B-pricerange', 'restaurant': 'O'}\n",
      "unknown slots {'food': None, 'pricerange': 'expensive', 'area': None, 'phone': None, 'addr': None, 'postcode': None, 'name': None}\n",
      "{'intent_detection': {'expensive restaurant': 'inform_pricerange'}, 'language': {'expensive restaurant': 'en'}, 'slots': {'food': None, 'pricerange': 'expensive', 'area': None, 'phone': None, 'addr': None, 'postcode': None, 'name': None}, 'unknown_slots': ['food', 'area', 'phone', 'addr', 'postcode', 'name']}\n",
      "unknown slots {'food': None, 'pricerange': 'expensive', 'area': None, 'phone': None, 'addr': None, 'postcode': None, 'name': None}\n",
      "GET NER TAG {'americain': 'B-food'}\n",
      "unknown slots {'food': 'americain', 'pricerange': 'expensive', 'area': None, 'phone': None, 'addr': None, 'postcode': None, 'name': None}\n",
      "{'intent_detection': {'americain': 'inform_food'}, 'language': {'americain': 'fr'}, 'slots': {'food': 'americain', 'pricerange': 'expensive', 'area': None, 'phone': None, 'addr': None, 'postcode': None, 'name': None}, 'unknown_slots': ['area', 'phone', 'addr', 'postcode', 'name']}\n",
      "unknown slots {'food': 'americain', 'pricerange': 'expensive', 'area': None, 'phone': None, 'addr': None, 'postcode': None, 'name': None}\n",
      "GET NER TAG {'west': 'B-area'}\n",
      "unknown slots {'food': 'americain', 'pricerange': 'expensive', 'area': 'west', 'phone': None, 'addr': None, 'postcode': None, 'name': None}\n",
      "{'intent_detection': {'west': 'inform_area'}, 'language': {'west': 'en'}, 'slots': {'food': 'americain', 'pricerange': 'expensive', 'area': 'west', 'phone': None, 'addr': None, 'postcode': None, 'name': None}, 'unknown_slots': ['phone', 'addr', 'postcode', 'name']}\n",
      "unknown slots {'food': 'americain', 'pricerange': 'expensive', 'area': 'west', 'phone': None, 'addr': None, 'postcode': None, 'name': None}\n",
      "GET NER TAG {'merci': 'B-food', 'au': 'B-food', 'revoir': 'B-food'}\n",
      "unknown slots {'food': 'revoir', 'pricerange': 'expensive', 'area': 'west', 'phone': None, 'addr': None, 'postcode': None, 'name': None}\n",
      "{'intent_detection': {'merci au revoir': 'bye__thankyou'}, 'language': {'merci au revoir': 'fr'}, 'slots': {'food': 'revoir', 'pricerange': 'expensive', 'area': 'west', 'phone': None, 'addr': None, 'postcode': None, 'name': None}, 'unknown_slots': ['phone', 'addr', 'postcode', 'name']}\n"
     ]
    }
   ],
   "source": [
    "bot = TelegramConnector('5315229065:AAFfKjvkYTpYLLAGpBQa7goxJQrQwvFOb0s')\n",
    "\n",
    "provider = PollingRequestProvider(bot=bot)\n",
    "\n",
    "runner = ScriptRunner(\n",
    "    script=script,\n",
    "    start_label=(\"global_flow\", \"start_node\"),\n",
    "    fallback_label=(\"global_flow\", \"fallback_node\"),\n",
    "    db=dict(),\n",
    "    request_provider=provider,\n",
    "    pre_annotators=[get_some_intent, get_ner_tag],\n",
    "    post_annotators=[print_misc],\n",
    ")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    runner.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae1316d-a411-4ea6-9dfa-bd4802c87d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bd5b18-6323-448d-a715-4cb803a608aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
